{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FW1_zf0rclii"
   },
   "source": [
    "This project is inspired by  standford project report. Both pdf and the github repository of the GAN models for this project are added as follows for the Reference:\n",
    "\n",
    "* https://github.com/goldhuang/SRGAN-PyTorch\n",
    "\n",
    "* http://cs230.stanford.edu/projects_fall_2018/reports/12445558.pdf\n",
    "\n",
    "\n",
    "Also, to calculate the Multi-Scale Structural Similarity (SSIM) index, we used the following repo as our reference\n",
    "\n",
    "* https://github.com/jorge-pessoa/pytorch-msssim\n",
    "\n",
    "\n",
    "\n",
    "To compute QILV, we converted codes gained from mathlab function by following address to the Python\n",
    "* https://www.mathworks.com/matlabcentral/fileexchange/36950-quality-index-based-on-local-variance-qilv\n",
    "\n",
    "* source : http://poseidon.tel.uva.es/~santi/personal/embc06.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folowoing labriries are recommended to be installed to support memory footprint libraries/code for using the GPU \n",
    "\n",
    "\n",
    "* !pip install gputil\n",
    "* !pip install psutil\n",
    "* !pip install humanize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ssim calculation libraries \n",
    "import math\n",
    "from math import exp\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "# import liberaries for Data utils \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms\n",
    "from torchvision.transforms import Compose, RandomCrop, CenterCrop, Resize, ToTensor, ToPILImage, Normalize\n",
    "\n",
    "# import liberaries for model classes \n",
    "import torch\n",
    "from torchvision import models, datasets\n",
    "from torch import nn,optim\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.nn import SyncBatchNorm\n",
    "from collections import OrderedDict\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "# import liberaries for train and validation the SRGAN model \n",
    "\n",
    "from math import log10\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.utils.data \n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "start_localtime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "\n",
    "\n",
    "# import the liberaries to support memory footprint libraries/code for using the GPU\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5BrM43Y9_JA"
   },
   "outputs": [],
   "source": [
    "# psutil is a cross-platform library for retrieving information on running processes and system utilization (CPU, memory, disks, network)\n",
    "# humanize offers various utilities which can be used on the numbers to make the numbers easily readable for the humans. \n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "\n",
    "printm() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ooSXNHPItWD"
   },
   "outputs": [],
   "source": [
    "# This project could run in Colab (if running from the computer, only importing the calsses is necesseray)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    " \n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "\n",
    "# Replace id# with an appropriate Key gained from the colab drive\n",
    "quality_assessment= drive.CreateFile({'id': 'id#'})\n",
    "quality_assessment.GetContentFile('quality.py')\n",
    "\n",
    "models= drive.CreateFile({'id': 'id#'})\n",
    "models.GetContentFile('models.py')\n",
    "\n",
    "dataloader= drive.CreateFile({'id': 'id#'})\n",
    "dataloader.GetContentFile('dataloader.py')\n",
    "\n",
    "getparam= drive.CreateFile({'id': 'id#'})\n",
    "getparam.GetContentFile('getparam.py')\n",
    "\n",
    "\n",
    "# After authentication, we can import our file liberiries as follow.\n",
    "from quality import *\n",
    "from models import *\n",
    "from dataloader import *\n",
    "from getparam import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29DSrchUBhkd"
   },
   "outputs": [],
   "source": [
    "# initialize the parameters \n",
    "\n",
    "#####################################\n",
    "crop_size =256\n",
    "upscale_factor=4  # the upscale_factor can be changed based on the paper\n",
    "num_batch_size= 1\n",
    "model='wa_srgan_WN'\n",
    "num_epoch=500\n",
    "chech_point=-1\n",
    "n_epoch_pretrain = 2\n",
    "#################################\n",
    "\n",
    "learning_rate=1e-3\n",
    "lr_decay_steps=200\n",
    "lr_decay_gamma=0.5\n",
    "seed=1\n",
    "rgb_mean=[0.4488,0.4371,0.4040]\n",
    "rgb_range=(0.0,255.0)\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "# if there is GPU, train from GPU\n",
    "device= ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "str_root='/content/drive' # if running from Colab\n",
    "\n",
    "# the folders that will be used during the training\n",
    "train_dataset_dir= str_root+'data/Data/train_HR'\n",
    "val_dataset_dir= str_root+'data/Data/valid_HR'\n",
    "epoch_path_valing= str_root+'data/epoch/'\n",
    "str_statistics= str_root+'data/statistics/'\n",
    "str_results= str_root+'data/training_results/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dr-uBzsWBhki"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the images in the train loaders\n",
    "train_set= TrainDatasetFromFolder(train_dataset_dir, crop_size=crop_size, upscale_factor=upscale_factor)\n",
    "val_set=ValDatasetFromFolder(val_dataset_dir, upscale_factor=upscale_factor,crop_size=crop_size)\n",
    "trian_loader=DataLoader(train_set, batch_size=num_batch_size, shuffle=True, num_workers=256)\n",
    "val_loader=DataLoader(val_set, batch_size=1, shuffle=False, num_workers=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19843,
     "status": "ok",
     "timestamp": 1593504657064,
     "user": {
      "displayName": "FAEZEHSADAT SHAHIDI MAN181002",
      "photoUrl": "",
      "userId": "15928786153813768879"
     },
     "user_tz": -480
    },
    "id": "c8euL7P7YOu7",
    "outputId": "130087c6-715b-43af-a58e-06c60b25fb87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator_Self_Attention_WGAN_WDSR_WN(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (Resblock_wdsr): Sequential(\n",
      "    (0): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): ResBlock_wdsr_WN(\n",
      "      (module): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (block10): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (self_atten): Self_Attention(\n",
      "    (query_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (key_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (value_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (block11): Sequential(\n",
      "    (0): UpsampleBlocks_wdsr(\n",
      "      (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (pixel_shuffle): PixelShuffle(upscale_factor=2)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (1): UpsampleBlocks_wdsr(\n",
      "      (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (pixel_shuffle): PixelShuffle(upscale_factor=2)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (2): Conv2d(64, 3, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
      "  )\n",
      ")\n",
      "Discriminator_Self_Attention_WGAN_WN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): PReLU(num_parameters=1)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): PReLU(num_parameters=1)\n",
      "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): PReLU(num_parameters=1)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): PReLU(num_parameters=1)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Self_Attention(\n",
      "      (query_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (key_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (value_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): PReLU(num_parameters=1)\n",
      "    (4): AdaptiveAvgPool2d(output_size=1)\n",
      "    (5): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (6): PReLU(num_parameters=1)\n",
      "    (7): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Vgg 19 has already pre trained. The weights are loaded to calculate the loss\n",
    "state_dict_vgg=torch.load(str_root+\"vgg19.pth\")\n",
    "# set the model, loss fucnction(critirion) and optimization function\n",
    "netG=Generator_Self_Attention_WGAN_WDSR_WN(upscale_factor)\n",
    "netD=Discriminator_Self_Attention_WGAN_WN()\n",
    "critirion=nn.MSELoss()\n",
    "generator_critirion=GeneratorLoss(state_dict_vgg,model)\n",
    "optimizerG=optim.Adam(netG.parameters(),lr=1e-4)\n",
    "optimizerD=optim.Adam(netD.parameters(),lr=1e-4)\n",
    "\n",
    "# print the G and D models \n",
    "print(netG)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "AMcjkYz3scD3",
    "outputId": "d4f20a3d-66c0-4c0d-e028-ec735b52e5ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wa_srgan_WN model training is about to start ... you may find the results in the data/ folder\n",
      "Start time : 2020-06-30 08:10:39 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/2] Loss_G: 0.0020: 100%|██████████| 2000/2000 [02:04<00:00, 16.07it/s]\n",
      "[2/2] Loss_G: 0.0019: 100%|██████████| 2000/2000 [02:05<00:00, 15.91it/s]\n",
      "[1/500] Loss_d: 0.1090, Loss_g: -0.0186, D(x): 0.9278, D(G(z)) : 0.8746, D grads:(0.709609, 0.338008) G grads:(0.000135, 0.000070): 100%|██████████| 2000/2000 [06:16<00:00,  5.32it/s]\n",
      "[converting LR images to SR ones with 4 upscale]  mse: 0.0078 db PSNR: 20.8912 db SSIM: 0.7994 db MSSSIM: 0.9532 db QILV: 0.9033 : 100%|██████████| 301/301 [00:46<00:00,  6.43it/s]\n",
      "[saving training results]: 100%|██████████| 301/301 [00:00<00:00, 729.11it/s]\n",
      "[2/500] Loss_d: 0.0150, Loss_g: -0.0265, D(x): 0.9990, D(G(z)) : 0.9925, D grads:(0.725749, 0.357063) G grads:(0.000105, 0.000055):  45%|████▍     | 896/2000 [03:01<03:09,  5.84it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Trianing, and validating the WA-SRGAN model\n",
    "\n",
    "print('%s model training is about to start ... you may find the results in the data/ folder' % (model))\n",
    "print('Start time : %s '%(start_localtime))\n",
    "end_localtime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "#get the parameters name of the top and the bottom of the netD and netG\n",
    "netG_param_top,netG_param_bottom=get_param_names(netG)\n",
    "netD_param_top,netD_param_bottom=get_param_names(netD)\n",
    "\n",
    "\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "netD.to(device)\n",
    "netG.to(device)\n",
    "generator_critirion.to(device)\n",
    "if chech_point==-1:\n",
    "  # optimizerG = optim.Adam(netG.parameters())\n",
    "  for epoch in range(1, n_epoch_pretrain + 1):\n",
    "    pre_train_bar = tqdm(trian_loader)\n",
    "    netG.train()\n",
    "    pre_trained_running_results = {'g_loss': 0, 'pre_training_num':0}\n",
    "    for target, data in pre_train_bar:\n",
    "      real_img=target.to(device)\n",
    "      data=data.to(device)\n",
    "      fake_img=netG(data)\n",
    "\n",
    "      # Train G\n",
    "      netG.zero_grad()\n",
    "      image_loss = critirion(fake_img, real_img)\n",
    "      pre_trained_running_results['g_loss'] += image_loss\n",
    "      pre_trained_running_results['pre_training_num'] += 1\n",
    "      image_loss.backward()\n",
    "      optimizerG.step()\n",
    "\n",
    "      # Print information by tqdm\n",
    "      pre_train_bar.set_description(desc='[%d/%d] Loss_G: %.4f' % (epoch, n_epoch_pretrain, image_loss))\n",
    "\n",
    "\n",
    "\n",
    "results={'d_loss':[], 'g_loss':[],'d_score':[], 'g_score':[],'psnr':[],'ssim':[],'psnr_lr':[],'ssim_lr':[],'dtg':[], 'dbg':[], 'gtg':[], 'gbg':[],'msssim':[],'qilv':[],'mse':[] ,'msssim_lr':[],'qilv_lr':[],'mse_lr':[] }\n",
    "# pre train the generator beforehand \n",
    "\n",
    "for epoch in range(1, num_epoch+1):\n",
    "  train_bar=tqdm(trian_loader)\n",
    "  running_results={'batch_sizes':0, 'd_loss':0, 'g_loss':0, 'g_score':0, 'd_score':0, 'training_num':0,'dtg':0, 'dbg':0, 'gtg':0, 'gbg':0 }\n",
    "  netG.train()\n",
    "  netD.train()\n",
    "  for target, data  in train_bar:\n",
    "    batch_size=data.size(0)\n",
    "    running_results['batch_sizes']+=batch_size\n",
    "    running_results['training_num']+=1\n",
    "    ########################################\n",
    "    #update D-network min(D(G(z))-D(x)+ 10* (second gradient on the (norm of( gradient of X- gradient of Xhat / x-xhat))-1).mean\n",
    "    # {mean is because we have batch size}\n",
    "    #########################################\n",
    "    real_img=Variable(target)\n",
    "    z=Variable(data)\n",
    "    # if torch.cuda.is_available():\n",
    "    real_img=real_img.to(device)\n",
    "    z=z.to(device)\n",
    "    fake_img=netG(z)\n",
    "    netD.zero_grad()\n",
    "    \n",
    "    ###########################\n",
    "    # 1- train with real\n",
    "    #############################\n",
    "    real_out=torch.mean(netD(real_img))\n",
    "    # real_out.backward()\n",
    "    #############################\n",
    "    # 2-  # train with fake\n",
    "    ##############################\n",
    "    fake_out=torch.mean(netD(fake_img))\n",
    "\n",
    "    #################################\n",
    "    gradient_penalty = calc_gradient_penalty(netD, real_img, fake_img, device)\n",
    "    d_loss = fake_out - real_out + 10*gradient_penalty\n",
    "    running_results['d_loss']+=torch.sigmoid(d_loss).item()\n",
    "    d_loss.backward(retain_graph=True)\n",
    "    # Wasserstein_D = fake_out-real_out\n",
    "    optimizerD.step()\n",
    "    \n",
    "    dtg, dbg = get_grads_D(netD,netD_param_top,netD_param_bottom)\n",
    "    ###############################\n",
    "    #update G-network min(1-D(G(z))+perception_loss+Image_loss+TV_loss)\n",
    "    netG.zero_grad()\n",
    "    g_loss=generator_critirion(fake_out.item(), fake_img, real_img)\n",
    "    running_results['g_loss']+=g_loss.item()\n",
    "    g_loss.backward()\n",
    "    fake_img=netG(z)\n",
    "    fake_out=torch.mean(netD(fake_img))\n",
    "    optimizerG.step()\n",
    "    gtg, gbg = get_grads_G(netG,netG_param_top,netG_param_bottom)\n",
    "    #loss for current batch before optimization\n",
    "    \n",
    "    running_results['g_score']+=torch.sigmoid(fake_out).item()\n",
    "    running_results['d_score']+=torch.sigmoid(real_out).item()\n",
    "    running_results['dtg']+=dtg.item()\n",
    "    running_results['dbg']+=dbg.item()\n",
    "    running_results['gtg']+=gtg.item()\n",
    "    running_results['gbg']+=gbg.item()\n",
    "    train_bar.set_description(desc='[%d/%d] Loss_d: %.4f, Loss_g: %.4f, D(x): %.4f, D(G(z)) : %.4f, D grads:(%f, %f) G grads:(%f, %f)' % \n",
    "                              (epoch,num_epoch, \n",
    "                               running_results['d_loss']/running_results['training_num'] ,\n",
    "                               running_results['g_loss']/running_results['training_num'] ,\n",
    "                               running_results['d_score']/running_results['training_num'] ,\n",
    "                               running_results['g_score']/running_results['training_num'] , \n",
    "                               running_results['dtg']/running_results['training_num'] ,\n",
    "                               running_results['dbg']/running_results['training_num'] ,\n",
    "                               running_results['gtg']/running_results['training_num'] ,\n",
    "                               running_results['gbg']/running_results['training_num'] \n",
    "        \n",
    "                       \n",
    "                            ))\n",
    "  netG.eval()\n",
    "  out_path= str_results\n",
    "  # if not os.out_path.exists():\n",
    "  #   os.makedirs(out_path)\n",
    "  with torch.no_grad():\n",
    "    val_bar=tqdm(val_loader)\n",
    "    valing_results={'mse':0, 'ssims': 0, 'psnr':0, 'ssim':0,'batch_sizes':0 ,'valing_num':0,\n",
    "                    'msssim':0,'qilv':0,'mse_lr':0, 'ssims_lr': 0, 'psnr_lr':0, 'ssim_lr':0,'msssim_lr':0,'qilv_lr':0,'max_value':0}\n",
    "    val_images=[]\n",
    "    for val_lr, val_hr_restore, val_hr in val_bar:\n",
    "        batch_size=val_lr.size(0)\n",
    "        valing_results['batch_sizes']+=batch_size\n",
    "        valing_results['valing_num']+=1\n",
    "        lr=val_lr\n",
    "        hr=val_hr\n",
    "        hr_bicubic=val_hr_restore\n",
    "        lr=lr.to(device)\n",
    "        hr=hr.to(device)\n",
    "        hr_bicubic=hr_bicubic.to(device)\n",
    "        sr=netG(lr)\n",
    "\n",
    "        if model=='wdsr':\n",
    "          sr_quantize=quantize(sr,rgb_range)\n",
    "          mse = ((sr_quantize - hr) ** 2).data.mean()\n",
    "          valing_results['mse'] += mse.item()\n",
    "          psnr = 10 * log10(255.0/(valing_results['mse'] / valing_results['valing_num']))\n",
    "        else:\n",
    "          mse = ((sr - hr) ** 2).data.mean()\n",
    "          valing_results['mse'] += mse.item()\n",
    "          psnr = 10 * log10(1.0/(valing_results['mse'] / valing_results['valing_num']))\n",
    "\n",
    "        mse_lr=((hr_bicubic - hr) ** 2).data.mean()\n",
    "        valing_results['mse_lr'] += mse_lr.item()\n",
    "        psnr_lr = 10 * log10(1/(valing_results['mse_lr'] / valing_results['valing_num']))\n",
    "       \n",
    "        batch_ssim=ssim(sr,hr).item()\n",
    "        batch_ssim_lr=ssim(hr_bicubic,hr).item()\n",
    "        valing_results['psnr']+=psnr\n",
    "        valing_results['psnr_lr']+=psnr_lr\n",
    "        valing_results['ssim']+=batch_ssim\n",
    "        valing_results['ssim_lr']+=batch_ssim_lr\n",
    "        valing_results['msssim']+=msssim(sr,hr).item()\n",
    "        valing_results['msssim_lr']+=msssim(hr_bicubic,hr).item()\n",
    "        valing_results['qilv']+=qilv(sr,hr).item()\n",
    "        valing_results['qilv_lr']+=qilv(hr_bicubic,hr).item()\n",
    "\n",
    "        val_bar.set_description(desc='[converting LR images to SR ones with %d upscale]  mse: %.4f db PSNR: %.4f db SSIM: %.4f db MSSSIM: %.4f db QILV: %.4f '% \n",
    "                                (upscale_factor,mse,psnr,batch_ssim,msssim(sr,hr).item(),qilv(sr,hr).item(),))\n",
    "        val_images.extend([\n",
    "                          display_transform(crop_size)(val_hr_restore.squeeze(0)),\n",
    "                          display_transform(crop_size)(hr.data.cpu().squeeze(0)),\n",
    "                          display_transform(crop_size)(sr.data.cpu().squeeze(0))\n",
    "                          ])\n",
    "    \n",
    "    val_images =torch.stack(val_images)\n",
    "    val_images=torch.chunk(val_images, val_images.size(0)//3)\n",
    "    val_save_bar=tqdm(val_images, desc='[saving training results]')\n",
    "    index=1\n",
    "    for image in val_save_bar :\n",
    "      image = utils.make_grid(image, nrow=3, padding=5)\n",
    "      if index <=2:\n",
    "        utils.save_image(image, out_path+model+'_epoch_%d_size_%d_upscale_%d_index_%d.png'%(epoch,crop_size,upscale_factor,index), padding=5)\n",
    "      index+=1\n",
    "    # for index in range(1,11):\n",
    "    # image= next(iter(val_save_bar))\n",
    "    # image = utils.make_grid(image, nrow=3, padding=5)\n",
    "    # utils.save_image(image, out_path+'epoch_%d_index_%d.png'%(epoch, index), padding=5)\n",
    "  #save model parameters \n",
    "  \n",
    "  torch.save(netG.state_dict(), epoch_path_valing +model+'_netG_epoch_%d_%d_%d.pth'%(epoch, crop_size, upscale_factor))\n",
    "  torch.save(netD.state_dict(), epoch_path_valing+model+'_netD_epoch_%d_%d_%d.pth'%(epoch, crop_size, upscale_factor))\n",
    "  #save loss/score/psnr/ssim\n",
    "  results['d_loss'].append(running_results['d_loss']/running_results['training_num'] )\n",
    "  results['g_loss'].append(running_results['g_loss']/running_results['training_num'])\n",
    "  results['d_score'].append(running_results['d_score']/running_results['training_num'] )\n",
    "  results['g_score'].append(running_results['g_score']/running_results['training_num'])\n",
    "  results['dtg'].append(running_results['dtg']/running_results['training_num'])\n",
    "  results['dbg'].append(running_results['dbg']/running_results['training_num'])\n",
    "  results['gtg'].append(running_results['gtg']/running_results['training_num'])\n",
    "  results['gbg'].append(running_results['gbg']/running_results['training_num'])\n",
    "  results['mse'].append(valing_results['mse']/valing_results['valing_num'])\n",
    "  results['mse_lr'].append(valing_results['mse_lr']/valing_results['valing_num'])\n",
    "  results['psnr'].append(valing_results['psnr']/valing_results['valing_num'])\n",
    "  results['psnr_lr'].append(valing_results['psnr_lr']/valing_results['valing_num'])\n",
    "  results['ssim'].append(valing_results['ssim']/valing_results['valing_num'])\n",
    "  results['ssim_lr'].append(valing_results['ssim_lr']/valing_results['valing_num'])\n",
    "  results['msssim'].append(valing_results['msssim']/valing_results['valing_num'])\n",
    "  results['msssim_lr'].append(valing_results['msssim_lr']/valing_results['valing_num'])\n",
    "  results['qilv'].append(valing_results['qilv']/valing_results['valing_num'])\n",
    "  results['qilv_lr'].append(valing_results['qilv_lr']/valing_results['valing_num'])\n",
    " \n",
    "  if epoch % 1 == 0 and epoch !=0:\n",
    "    out_path= str_statistics\n",
    "    data_frame=pd.DataFrame(\n",
    "        data={\n",
    "            'Loss_D':results['d_loss'],\n",
    "            'Loss_G':results['g_loss'],\n",
    "            'Score_D':results['d_score'],\n",
    "            'Score_G':results['g_score'],\n",
    "            'PSNR':results['psnr'],\n",
    "            'PSNR_BICUBIC':results['psnr_lr'],\n",
    "            'MSE':results['mse'],\n",
    "            'MSE_BICUBIC':results['mse_lr'],\n",
    "            'SSIM':results['ssim'],\n",
    "            'SSIM_BICUBIC':results['ssim_lr'],\n",
    "            'MSSSIM':results['msssim'],\n",
    "            'MSSSIM_BICUBIC':results['msssim_lr'],\n",
    "            'QILV':results['qilv'],\n",
    "            'QILV_BICUBIC':results['qilv_lr'],\n",
    "            'd_top_grad':results['dtg'],\n",
    "            'd_bot_grad':results['dbg'],\n",
    "            'g_top_grad':results['gtg'],\n",
    "            'g_bot_grad':results['gbg'],\n",
    "         \n",
    "        },\n",
    "        index=range(1,epoch+1)\n",
    "    )\n",
    "    data_frame.to_csv(out_path+model+'_size_'+ str(crop_size) +'_upscale_'+str(upscale_factor)+ '_eval_results.csv', index_label=\"Epoch\")\n",
    "\n",
    "end_localtime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "print('End time : %s '%(end_localtime))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "1-WA-SRGAN_256_x4_WN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
